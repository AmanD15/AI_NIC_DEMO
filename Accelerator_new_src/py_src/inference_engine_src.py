
import argparse
import python2llvm as llvm
from python2llvm import jit
from types_llvm import *
from pragmas import *
from pragmas import __loop_pipelining_on__
from functions import __bit_select__, __slice__, __concat__

parser = argparse.ArgumentParser()
parser.add_argument('-v', '--verbose', action='count', default=0)
args = parser.parse_args()
verbose = args.verbose

parser = argparse.ArgumentParser()
parser.add_argument('-v', '--verbose', action='count', default=0)
args = parser.parse_args()
verbose = args.verbose
ker: int8 = [[[0, 0, 0], [0, 0, 0], [0, 0, 0]]]
inp: uint8 = [[[0, 0, 0], [0, 0, 0], [0, 0, 0]]]
kerLinear: int8 = [0, 0, 0]
inpLinear: uint8 = [0, 0, 0]
'conv_final.ipynb\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1Yfn7xUzHqpWAq4BBXgDAx5uvP6ansYyQ\n'


# @llvm.jit(verbose=True)
# def fpdivide325(number1: float32, number2: float32) -> float32:
#     return number1 / number2

@llvm.jit(verbose=True)
def fp32_mul_for_ecg(number1: float32, number2: float32) -> float32:
    return number1 * number2


@llvm.jit(verbose=True)
def fp32_add_for_ecg(number1: float32, number2: float32) -> float32:
    return number1 + number2


@llvm.jit(verbose=True)
def fp32_sub_for_ecg(number1: float32, number2: float32) -> float32:
    return number1 - number2

@llvm.jit(verbose=True)
def fpcmp32(number1: float32, number2: float32, flag: bool) -> uint2:
    if number1 == number2:
        val = 0
    elif number1 < number2:
        val = 1
    elif number1 > number2:
        val = 2
    else:
        val = 3
    return val 

@llvm.jit(verbose=True)
def fstoi_for_ecg(number1: float32) -> int32:
    return int(number1) 

@llvm.jit(verbose=True)
def fitos32_for_ecg(number1: uint32) -> float32:
    return float(number1) 

@llvm.jit(verbose=True)
def round_half_even(number: float32) -> uint8:
    integer_part_int = fstoi_for_ecg(number)
    integer_part = fitos32_for_ecg(integer_part_int)
    fractional_part = fp32_sub_for_ecg(number, integer_part)
    cmp_result = fpcmp32(fractional_part, 0.5, 1)
    if cmp_result == 1:
        rounded_integer = integer_part
    elif cmp_result == 2:
        rounded_integer = integer_part + 1
    elif integer_part_int % 2 == 0:
         rounded_integer = integer_part
    else:
        rounded_integer = integer_part + 1  
    return rounded_integer

@llvm.jit(verbose=True)
def uint_quant(val: float32, scale_inv: float32, zero_point: float32) -> uint8:
    out: float32 = fp32_add_for_ecg(fp32_mul_for_ecg(val, scale_inv), zero_point)
    if out > 255.0:
        out: float32 = 255.0
    if out < 0.0:
        out: float32 = 0.0
    round_out = round_half_even(out)
    return round_out

@llvm.jit(verbose=True)
def dequant_inp(val: uint8, scale: float32, zero_point: float32) -> float32:
    float_val = val
    out = fp32_mul_for_ecg(scale, fp32_sub_for_ecg(float_val, zero_point))
    return out

@llvm.jit(verbose=True)
def dequant_ker(val: int8, scale: float32, zero_point: float32) -> float32:
    float_val = val
    out = fp32_mul_for_ecg(scale, fp32_sub_for_ecg(float_val, zero_point))
    return out

@llvm.jit(verbose=True)
def relu(val: float32) -> float32:
    if val > 0:
        return val
    return 0

@llvm.jit(verbose=True)
def convolution_new(groups: int32, reuseInp: uint32, reuseData: bool, ker_size: int32, inp_scale: float32, inp_zero_point: float32, ker_scale: float32, ker_zero_point: float32, conv_scale: float32, conv_zero_point: float32, isLinear: bool, in_channels: int32, isActivation: bool) -> uint8:
    convOutVal: float32 = 0.0
    counter = 0
    if isLinear:
        for grp_no in range(groups):
            num_chn_present = 0
            if in_channels >= 8 * (grp_no + 1):
                num_chn_present = 8
            else:
                num_chn_present = in_channels - 8 * grp_no
            
            for chn_no in range(num_chn_present):
                __loop_pipelining_on__(31, 7, 1)
                inp_val = read_uint32('in_data_0')
                ker_val = read_uint32('ker_data')
                inp_val_new = inp_val
                ker_val_new = ker_val

                # inp_val_flat = read_uint32('flatten_data')
                if reuseData:
                    write_uint32('in_data_0', inp_val_new)

                dot_product = fp32_mul_for_ecg(inp_val_new, ker_val_new)
                if counter%2 == 0:
                    write_uint32('accumulator_pipe_even', dot_product)
                else:
                    write_uint32('accumulator_pipe_odd', dot_product)
                counter = counter + 1
        return 
    
    for grp_no in range(groups):
        for colInd in range(ker_size):
            for rowInd in range(ker_size):
                num_chn_present = 0
                if in_channels >= 8 * (grp_no + 1):
                    num_chn_present = 8
                else:
                    num_chn_present = in_channels - 8 * grp_no
                
                for chn_no in range(num_chn_present):
                    __loop_pipelining_on__(31, 7, 1)
                    if colInd == 0:
                        inp_val = read_uint32('in_data_0')
                    elif colInd == 1:
                        inp_val = read_uint32('in_data_1')
                    elif colInd == 2:
                        inp_val = read_uint32('in_data_2')
                    elif colInd == 3:
                        inp_val = read_uint32('in_data_3')
                    elif colInd == 4:
                        inp_val = read_uint32('in_data_4')

                    ker_val = read_uint32('ker_data')

                    if reuseData:
                        write_uint32('ker_data', ker_val)

                        if reuseInp == 1:
                            if colInd == 1:
                                write_uint32('in_data_0', inp_val)
                            elif colInd == 2:
                                write_uint32('in_data_1', inp_val)
                            elif colInd == 3:
                                write_uint32('in_data_2', inp_val)
                            elif colInd == 4:
                                write_uint32('in_data_3', inp_val)

                        elif reuseInp == 2:
                            if colInd == 0:
                                write_uint32('in_data_1', inp_val)
                            elif colInd == 1:
                                write_uint32('in_data_2', inp_val)
                            elif colInd == 2:
                                write_uint32('in_data_3', inp_val)
                            elif colInd == 3:
                                write_uint32('in_data_4', inp_val)

                        elif reuseInp == 0:
                            if rowInd > 0:
                                if colInd == 0:
                                    write_uint32('in_data_0', inp_val)
                                elif colInd == 1:
                                    write_uint32('in_data_1', inp_val)
                                elif colInd == 2:
                                    write_uint32('in_data_2', inp_val)
                                elif colInd == 3:
                                    write_uint32('in_data_3', inp_val)
                                elif colInd == 4:
                                    write_uint32('in_data_4', inp_val)

                    inp_val_new = inp_val
                    ker_val_new = ker_val
                    dot_product = fp32_mul_for_ecg(inp_val_new, ker_val_new)
                    if counter%2 == 0:
                        write_uint32('accumulator_pipe_even', dot_product)
                    else:
                        write_uint32('accumulator_pipe_odd', dot_product)
                    counter = counter + 1
    return

@llvm.jit(verbose=True)
def accumulator(in_channels: uint32, ker_size: uint32, conv_scale: float32, conv_zero_point: float32,isActivation: bool, isLinear: bool) -> uint8:
    if isLinear:
        num_iterations = in_channels
    else:
        num_iterations = (in_channels*ker_size*ker_size)
    convOutVal: float32 = 0.0
    cur_iter = 0
    while(cur_iter<num_iterations):
        val_even = read_uint32('accumulator_pipe_even')
        cur_iter+=1

        if(cur_iter<num_iterations):
            val_odd = read_uint32('accumulator_pipe_odd')
        else:
            val_odd = 0
        convOutVal = fp32_add_for_ecg(convOutVal, fp32_add_for_ecg(val_even, val_odd))
        cur_iter+=1

    if isActivation:
        convOutVal = relu(convOutVal)
    convOut_quant = uint_quant(convOutVal, conv_scale, conv_zero_point)
    write_uint8('out_data', convOut_quant)
    return convOut_quant


@llvm.jit(verbose=True)
def readModule_convolution(base_address: uint32, addr: uint32) -> uint64:
    val: uint64 = 0
    return val


@llvm.jit(verbose=True)
def writeModule_convolution(base_address: uint32, addr: uint32, data: uint64, byte_mask: uint8):
    write_uint64('ker_data', data)

@llvm.jit(verbose=True)
def fetchKernelLinear(base_addr: uint32,  groups: uint32, chn_no: uint32,in_channels: int32,ker_scale: float32, ker_zero_point: float32):
    for grp_no in range(groups):
        data = readModule_convolution(base_addr, (8 * grp_no) + (groups * chn_no * 8))
        
        num_chn_present = 0
        if in_channels >= 8 * (grp_no + 1):
            num_chn_present = 8
        else:
            num_chn_present = in_channels - 8 * grp_no
        
        for chn_no in range(num_chn_present):
                                        
            if chn_no == 0:
                val = __slice__(data, 56, 63)
            elif chn_no == 1:
                val = __slice__(data, 48, 55)
            elif chn_no == 2:
                val = __slice__(data, 40, 47)                    
            elif chn_no == 3:
                val = __slice__(data, 32, 39)                    
            elif chn_no == 4:
                val = __slice__(data, 24, 31)                    
            elif chn_no == 5:
                val = __slice__(data, 16, 23)                    
            elif chn_no == 6:
                val = __slice__(data, 8, 15)                    
            elif chn_no == 7:
                val = __slice__(data, 0, 7)
            
            ker_dequant_val = dequant_ker(val, ker_scale, ker_zero_point)

            write_uint32('ker_data', ker_dequant_val)
        # write_uint64('ker_data', data)

@llvm.jit(verbose=True)
def fetchInputLinear(base_addr: uint32, groups: uint32, in_channels: int32, inp_scale: float32, inp_zero_point: float32):
    for grp_no in range(groups):
        data = readModule_convolution(base_addr, 8 * grp_no)
        num_chn_present = 0
        if in_channels >= 8 * (grp_no + 1):
            num_chn_present = 8
        else:
            num_chn_present = in_channels - 8 * grp_no
        
        for chn_no in range(num_chn_present):
                                        
            if chn_no == 0:
                val = __slice__(data, 56, 63)
            elif chn_no == 1:
                val = __slice__(data, 48, 55)
            elif chn_no == 2:
                val = __slice__(data, 40, 47)                    
            elif chn_no == 3:
                val = __slice__(data, 32, 39)                    
            elif chn_no == 4:
                val = __slice__(data, 24, 31)                    
            elif chn_no == 5:
                val = __slice__(data, 16, 23)                    
            elif chn_no == 6:
                val = __slice__(data, 8, 15)                    
            elif chn_no == 7:
                val = __slice__(data, 0, 7)
            
            inp_dequant_val = dequant_inp(val, inp_scale, inp_zero_point)

            write_uint32('in_data_0', inp_dequant_val)
        # write_uint64('in_data_0', data)

@llvm.jit(verbose=True)
def fetchKernel(base_addr: uint32, groups: uint32, ker_size: int32, in_channels: int32,ker_scale: float32, ker_zero_point: float32):
    # grp_no = 0
    for grp_no in range(groups):
        for col in range(ker_size):
            for row in range(ker_size):

                addr = ((8*groups) * ker_size * row) + ((8*groups) * col) + grp_no * 8
                data = readModule_convolution(base_addr, addr)
                
                num_chn_present = 0
                if in_channels >= 8 * (grp_no + 1):
                    num_chn_present = 8
                else:
                    num_chn_present = in_channels - 8 * grp_no
                
                for chn_no in range(num_chn_present):
                                                
                    if chn_no == 0:
                        val = __slice__(data, 56, 63)
                    elif chn_no == 1:
                        val = __slice__(data, 48, 55)
                    elif chn_no == 2:
                        val = __slice__(data, 40, 47)                    
                    elif chn_no == 3:
                        val = __slice__(data, 32, 39)                    
                    elif chn_no == 4:
                        val = __slice__(data, 24, 31)                    
                    elif chn_no == 5:
                        val = __slice__(data, 16, 23)                    
                    elif chn_no == 6:
                        val = __slice__(data, 8, 15)                    
                    elif chn_no == 7:
                        val = __slice__(data, 0, 7)
                    
                    ker_dequant_val = dequant_ker(val, ker_scale, ker_zero_point)

                    write_uint32('ker_data', ker_dequant_val)
                


@llvm.jit(verbose=True)
def fetchInpVerSlice(base_addr: uint32,groups: uint32, startRowIndex: int32, startColIndex: int32, grp_no: int32, ker_size: int32, padReq: bool, in_rows: int32, in_cols: int32, in_channels: int32, inp_scale: float32, inp_zero_point: float32):
    col = 0
    for row in range(ker_size):

        addr = ((8*groups) * in_cols * (startRowIndex + row)) + ((8*groups) * (startColIndex + col)) + grp_no * 8
        data: uint64 = readModule_convolution(base_addr, addr)

        num_chn_present = 0
        if in_channels >= 8 * (grp_no + 1):
            num_chn_present = 8
        else:
            num_chn_present = in_channels - 8 * grp_no
        
        for chn_no in range(num_chn_present):
                                        
            if chn_no == 0:
                val = __slice__(data, 56, 63)
            elif chn_no == 1:
                val = __slice__(data, 48, 55)
            elif chn_no == 2:
                val = __slice__(data, 40, 47)                    
            elif chn_no == 3:
                val = __slice__(data, 32, 39)                    
            elif chn_no == 4:
                val = __slice__(data, 24, 31)                    
            elif chn_no == 5:
                val = __slice__(data, 16, 23)                    
            elif chn_no == 6:
                val = __slice__(data, 8, 15)                    
            elif chn_no == 7:
                val = __slice__(data, 0, 7)
            
            inp_dequant_val = dequant_inp(val, inp_scale, inp_zero_point)

            if startRowIndex == 0 and startColIndex == 0:
                write_uint32('in_data_0', inp_dequant_val)
            elif startRowIndex == 0 and startColIndex == 1:
                write_uint32('in_data_1', inp_dequant_val)
            elif startRowIndex == 0 and startColIndex == 2:
                write_uint32('in_data_2', inp_dequant_val)
            elif startRowIndex == 0 and startColIndex == 3:
                write_uint32('in_data_3', inp_dequant_val)
            elif startRowIndex % 2 == 0:
                write_uint32('in_data_4', inp_dequant_val)
            else:
                write_uint32('in_data_0', inp_dequant_val)

@llvm.jit(verbose=True)
def fetchInpHorSlice(base_addr: uint32,groups: uint32, startRowIndex: int32, grp_no: int32, ker_size: int32, padReq: bool, in_rows: int32, in_cols: int32, in_channels: int32, out_cols: int32, inp_scale: float32, inp_zero_point: float32):
    row = ker_size
    if startRowIndex % 2 == 0:
        startColIndex: int32 = out_cols - 1
    else:
        startColIndex: int32 = 0
    for col in range(ker_size):
        for _ in range(8*(ker_size - 1)):
            if col == 0:
                inp_val = read_uint32('in_data_0')
                write_uint32('in_data_0', inp_val)
            elif col == 1:
                inp_val = read_uint32('in_data_1')
                write_uint32('in_data_1', inp_val)
            elif col == 2:
                inp_val = read_uint32('in_data_2')
                write_uint32('in_data_2', inp_val)
            elif col == 3:
                inp_val = read_uint32('in_data_3')
                write_uint32('in_data_3', inp_val)
            elif col == 4:
                inp_val = read_uint32('in_data_4')
                write_uint32('in_data_4', inp_val)
        # if padReq:
        #     if startRowIndex + row == 0 or startColIndex + col == 0 or startRowIndex + row == in_rows + 1 or (startColIndex + col == in_cols + 1):
        #         val: uint64 = fstoi_for_ecg(inp_zero_point)
        #     else:
        #         addr = in_channels * in_cols * (startRowIndex + row - 1) + in_channels * (startColIndex + col - 1) + grp_no * 8
        #         val: uint64 = readModule_convolution(base_addr, addr)
        # else:
        addr = ((8*groups) * in_cols * (startRowIndex + row)) + ((8*groups) * (startColIndex + col)) + grp_no * 8
        data: uint64 = readModule_convolution(base_addr, addr)

        num_chn_present = 0
        if in_channels >= 8 * (grp_no + 1):
            num_chn_present = 8
        else:
            num_chn_present = in_channels - 8 * grp_no
        
        for chn_no in range(num_chn_present):
                                        
            if chn_no == 0:
                val = __slice__(data, 56, 63)
            elif chn_no == 1:
                val = __slice__(data, 48, 55)
            elif chn_no == 2:
                val = __slice__(data, 40, 47)                    
            elif chn_no == 3:
                val = __slice__(data, 32, 39)                    
            elif chn_no == 4:
                val = __slice__(data, 24, 31)                    
            elif chn_no == 5:
                val = __slice__(data, 16, 23)                    
            elif chn_no == 6:
                val = __slice__(data, 8, 15)                    
            elif chn_no == 7:
                val = __slice__(data, 0, 7)
            
            inp_dequant_val = dequant_inp(val, inp_scale, inp_zero_point)

            if col == 0:
                write_uint32('in_data_0', inp_dequant_val)
            elif col == 1:
                write_uint32('in_data_1', inp_dequant_val)
            elif col == 2:
                write_uint32('in_data_2', inp_dequant_val)
            elif col == 3:
                write_uint32('in_data_3', inp_dequant_val)
            elif col == 4:
                write_uint32('in_data_4', inp_dequant_val)

@llvm.jit(verbose=True)
def pooling(pool_cols: int32):
    for i in range(pool_cols):
        r0_val0 = read_uint8('pool_data_fifo_r0')
        r0_val1 = read_uint8('pool_data_fifo_r0')
        r1_val0 = read_uint8('pool_data_lifo_r1')
        r1_val1 = read_uint8('pool_data_lifo_r1')
        if r0_val0 >= r0_val1 and r0_val0 >= r1_val0 and (r0_val0 >= r1_val1):
            maxPoolVal = r0_val0
        elif r0_val1 >= r0_val0 and r0_val1 >= r1_val0 and (r0_val1 >= r1_val1):
            maxPoolVal = r0_val1
        elif r1_val0 >= r0_val0 and r1_val0 >= r0_val1 and (r1_val0 >= r1_val1):
            maxPoolVal = r1_val0
        else:
            maxPoolVal = r1_val1
        write_uint8('pool_out_data', maxPoolVal)



@llvm.jit(verbose=True)
def convengine(in_start_addr: uint32, out_start_addr: uint32, ker_start_addr: uint32, out_grp_no: uint32, in_rows: int32, in_cols: int32, in_channels: int32, out_channels: uint32, groups: int32, ker_size: int32, pool_cols: int32, inp_scale: float32, inp_zero_point: float32, ker_scale: float32, ker_zero_point: float32, conv_scale: float32, conv_zero_point: float32, padReq: bool, poolReq: bool, isLinear: bool, isActivation: bool, isFlatten: bool, offsetStart:uint32, out_chn_ind: uint32) -> uint8:
    out_rows = in_rows - ker_size + 1
    out_cols = in_cols - ker_size + 1
    # pool_rows_float = fp32_add_for_ecg(fpdivide325(out_rows - pool_ker_size, pool_stride), 1.0)
    # pool_cols_float = fp32_add_for_ecg(fpdivide325(out_cols - pool_ker_size, pool_stride), 1.0)
    # pool_rows = fstoi_for_ecg(pool_rows_float)
    # pool_cols = fstoi_for_ecg(pool_cols_float)
    poolRowIndex: int32 = 0
    reuseInp: int32 = 1
    reuseData: bool = True
    flattenOutShift = 8
    flattenOutOffset = offsetStart
    if isLinear:
        for chn_no in range(out_channels):
            if chn_no == (out_channels - 1):
                reuseData = False
            fetchKernelLinear(ker_start_addr, groups, chn_no, in_channels, ker_scale, ker_zero_point)
            fetchInputLinear(in_start_addr, groups,in_channels, inp_scale, inp_zero_point)
            convolution_new(groups, reuseInp, reuseData, ker_size, inp_scale, inp_zero_point, ker_scale, ker_zero_point, conv_scale, conv_zero_point, isLinear, in_channels, isActivation)
            accumulator(in_channels,ker_size, conv_scale, conv_zero_point,isActivation, isLinear)

            conv_out = read_uint8('out_data')
            write_data_linear:uint64 = (conv_out << (8 * (flattenOutShift - 1)))
            byte_mask_linear = (1<<(flattenOutShift - 1))
            writeModule_convolution(out_start_addr, flattenOutOffset, write_data_linear, byte_mask_linear)
            flattenOutShift = flattenOutShift - 1
            if flattenOutShift == 0:
                flattenOutShift = 8
                flattenOutOffset = flattenOutOffset + 8
        
        # write_uint8('flatten_data', conv_out)
        return conv_out
    if padReq:
        out_rows = in_rows
        out_cols = in_cols
    
    
    fetchKernel(ker_start_addr, groups, ker_size, in_channels, ker_scale, ker_zero_point)

    for sliceNo in range(ker_size):
        for grp_no in range(groups):
            fetchInpVerSlice(in_start_addr,groups, 0, sliceNo, grp_no, ker_size, padReq, in_rows, in_cols, in_channels, inp_scale, inp_zero_point)
            
    for row_no in range(out_rows):
        for virtual_col_no in range(out_cols):

            if row_no == out_rows - 1 and virtual_col_no == out_cols - 1:
                reuseData = False
            else:
                reuseData = True

            if row_no % 2 == 0:
                reuseInp = 1
                col_no = virtual_col_no
                fetch_col_no = col_no + (ker_size - 1)
                pool_col_no = col_no - 2
            else:
                reuseInp = 2
                col_no = out_cols - virtual_col_no - 1
                fetch_col_no = col_no
                pool_col_no = col_no

            if virtual_col_no == out_cols - 1:
                reuseInp = 0

            if virtual_col_no > 0:
                for grp_no in range(groups):
                    fetchInpVerSlice(in_start_addr, groups, row_no, fetch_col_no, grp_no, ker_size, padReq, in_rows, in_cols, in_channels, inp_scale, inp_zero_point)

            convolution_new(groups, reuseInp, reuseData, ker_size, inp_scale, inp_zero_point, ker_scale, ker_zero_point, conv_scale, conv_zero_point, isLinear, in_channels, isActivation)
            accumulator(in_channels, ker_size, conv_scale, conv_zero_point,isActivation, isLinear)
            out = read_uint8('out_data')
            if poolReq:
                if row_no % 2 == 0:
                    write_uint8('pool_data_fifo_r0', out)
                else:
                    write_uint8('pool_data_lifo_r1', out)
        if poolReq:
            if row_no % 2 != 0:
                pooling(pool_cols)
                for poolColIndex in range(pool_cols):
                    conv_out = read_uint8('pool_out_data')
                    if not isFlatten:
                        addr = out_channels * pool_cols * poolRowIndex + out_channels * poolColIndex + 8 * out_grp_no
                        byte_mask = (1<<(7 - out_chn_ind))
                        write_data:uint64 = (conv_out << (8 * (7 - out_chn_ind)))
                        writeModule_convolution(out_start_addr, addr, write_data, byte_mask)
                    else:

                        write_data_flat:uint64 = (conv_out << (8 * (flattenOutShift - 1)))
                        byte_mask_flat = (1<<(flattenOutShift - 1))
                        writeModule_convolution(out_start_addr, flattenOutOffset, write_data_flat, byte_mask_flat)
                        flattenOutShift = flattenOutShift - 1
                        if flattenOutShift == 0:
                            flattenOutShift = 8
                            flattenOutOffset = flattenOutOffset + 8

                poolRowIndex += 1
        if row_no < out_rows - 1:
            for grp_no in range(groups):
                fetchInpHorSlice(in_start_addr,groups, row_no, grp_no, ker_size, padReq, in_rows, in_cols, in_channels, out_cols, inp_scale, inp_zero_point)
    return 0