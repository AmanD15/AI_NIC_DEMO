
/resnet/models/ 
    - qresnet.py - Code for ResNet 18 architecture
                    [Reference: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py]
    - quantize.py - Code for implementing forward and backward pass of 
                    Quantized Convolution Neural Network and also 
                    quantizing input data of convolution and weights
                    to 8 bits

/resnet/utils/ - folder contains helper code for finding accuracy and logging 

/resnet/preprocess.py - code for preprocessing the input data

/resnet/resnet_8bit.ipynb - Jupyter Notebook containing code for training and testing ResNet-18 architecture
                    with quantized 8-bit input and weights

/resnet/resnet_original.ipynb - Actual ResNet-18 architecture using float data type 

/lenet/lenet_float.ipynb - LeNet-5 architecture implementation using float datatype

/lenet/lenet_posit.ipynb - LeNet-5 architecture with float arithmetic. The input of each
                            convolution layer is first converted to 8-bit posit
                            and then converted back to 32 bit float. This is to simulate
                            the storage of 32 bit output of convolution to 8 bit posit
                            in the accelerator.

References
    - https://github.com/soon-yau/QNN/tree/master - Tutorial for understanding Quantized Neural Network

TODO

                                        Dataset     Training Accuracy     Testing Accuracy

ResNet-18 with 8-bit quantization       CIFAR-10          88 %                  82%

ResNet-18 with float data type          CIFAR-10          92 %                  86%

LeNet-5 with 8 bit posit                MNIST             94.59%                94.30%

LeNet-5 with 32 bit float               MNIST             96.48%                96.42%

Observations
    - Used tanh activation function, which gives the output values from -1 to 1
    - The max and min values for each convolution layer(for 32 bit float version)
         was between -1 to 1