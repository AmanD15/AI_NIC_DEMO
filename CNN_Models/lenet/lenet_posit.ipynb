{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIr5qOBm6e9I"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "I am starting a series of post in medium covering most of the CNN architectures implemented so far, in pytorch and tensorflow. I believe after getting your hands on with the standard architectures, we will be ready to build our own custom CNN architectures for any task.\n",
        "\n",
        "So I am starting with the oldest CNN architecture LeNet(1998). It was primarily developed for recognition of handwritten and other characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0OFJp296Ebs"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/700/1*lvvWF48t7cyRWqct13eU0w.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHrc6zHo79qw"
      },
      "source": [
        "The above picture summarizes the LeNet's architecture, let's break down each of them layer by layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldrx3_0V8ZaZ"
      },
      "source": [
        "## LeNet Architecture\n",
        "S.No | Layers | Output Shape (Height, Width, Channels)\n",
        "--- | --- | ---\n",
        "1 | Input Layer | 32 x 32 x 1\n",
        "2 | Conv2d [6 Filters of size = 5x5, stride = 1, padding = 0 ] | 28 x 28 x 6\n",
        "3 | Average Pooling [stride = 2, padding = 0] | 14 x 14 x 6\n",
        "4 | Conv2d [16 Filters of size = 5x5, stride = 1, padding = 0 ] | 10 x 10 x 16\n",
        "5 | Average Pooling [stride = 2, padding = 0] | 5 x 5 x 16\n",
        "6 | Conv2d [120 Filters of size = 5x5, stride = 1, padding = 0 ] | 1 x 1 x 120\n",
        "7 | Linear1 Layer | 120\n",
        "8 | Linear2 Layer | 84\n",
        "9 | Final Linear Layer | 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6h1Bup0z3Lu"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/330/1*D47ER7IArwPv69k3O_1nqQ.png\">\n",
        "\n",
        "## Number of Learning Parameters = [i x (f x f) x b] + b\n",
        "i = Number of input channels in conv2d\n",
        "\n",
        "f = Filter Size\n",
        "\n",
        "b = Number of Bias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK1Yaofcxg9H"
      },
      "source": [
        "## Output size calculation after applying convolution\n",
        "Stride and Padding are kept constants across the network, so S = 1, P = 0\n",
        "\n",
        "1. Input Layer shape = 32 x 32 x 1\n",
        "2. After applying conv2d with 6 filters of (5x5),\n",
        "  * Output shape = ((32 + 0 - 5) / 1) + 1 = 28\n",
        "  * No of Learning Parameters = ([ 1 x (5 * 5) x 1] + 1) * 6 filters = 156\n",
        "3. After applying Average Pooling (2x2),\n",
        "  * Output shape = ((28 + 0 - 2) / 2) + 1 = 14\n",
        "  * No of Learning Parameters = None (0)\n",
        "4. After applying conv2d with 16 filters of (5x5),\n",
        "  * Output shape = ((14 + 0 - 5) / 1) + 1 = 10\n",
        "  * No of Learning Parameters = ([ 6 x (5 * 5) x 1] + 1) * 16 filters = 2416\n",
        "5. After applying Average Pooling (2x2),\n",
        "  * Output shape = ((10 + 0 - 2) / 2) + 1 = 5\n",
        "  * No of Learning Parameters = None (0)\n",
        "6. After applying conv2d with 150 filters of (5x5),\n",
        "  * Output shape = ((5 + 0 - 5) / 1) + 1 = 1\n",
        "  * No of Learning Parameters = ([ 16 x (5 * 5) x 1] + 1) * 120 filters = 48120\n",
        "7. Apply Linear Layer of 84 neurons,\n",
        "  * No of Learning Parameters = (120 * 84 + 84) = 10164\n",
        "8. Apply Linear Layer of 10 neurons,\n",
        "  * No of Learning Parameters = (84 * 10 + 10) = 850\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5pnyu6WI41c",
        "outputId": "87ebeb04-d7f9-44de-b4ff-7ffc363360e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting softposit\n",
            "  Downloading softposit-0.3.4.4.tar.gz (118 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: softposit\n",
            "  Building wheel for softposit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for softposit: filename=softposit-0.3.4.4-cp310-cp310-linux_x86_64.whl size=374168 sha256=7e0ca41531f4732baee700adcbf94cc9c1a83c9ebdfd82590826e01a32b62570\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/f1/20/d5f8be9cc554fe2ec37ec65ddc64002b5bee71f44899e3e33c\n",
            "Successfully built softposit\n",
            "Installing collected packages: softposit\n",
            "Successfully installed softposit-0.3.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install softposit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n6rxu7NFIlpx"
      },
      "outputs": [],
      "source": [
        "# Importing necessary modules\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import softposit as sp\n",
        "\n",
        "!pip install torchsummaryX --quiet\n",
        "from torchsummaryX import summary as summaryX\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2xgkq3Y6Svj",
        "outputId": "0b509c39-4d40-4cfd-cc1e-a9bcd85cb519"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (linear1): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (linear2): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (tanh): Tanh()\n",
              "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def change_tensor_values(tensor):\n",
        "    shape = tensor.shape\n",
        "    flat = tensor.flatten()  # Flatten the tensor to a 1D array\n",
        "    # print(shape)\n",
        "    for i in range(len(flat)):\n",
        "      temp = sp.posit8(float(flat[i]))\n",
        "      flat[i] = float(temp)\n",
        "    return flat.reshape(shape)\n",
        "    # return flat.reshape(shape).type(torch.FloatTensor)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6,\n",
        "                           kernel_size = 5, stride = 1, padding = 0)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16,\n",
        "                           kernel_size = 5, stride = 1, padding = 0)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 120,\n",
        "                           kernel_size = 5, stride = 1, padding = 0)\n",
        "    self.linear1 = nn.Linear(120, 84)\n",
        "    self.linear2 = nn.Linear(84, 10)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = change_tensor_values(x)\n",
        "    x = self.conv1(x)\n",
        "    x = self.tanh(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = change_tensor_values(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.tanh(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = change_tensor_values(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.tanh(x)\n",
        "    x = change_tensor_values(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.linear1(x)\n",
        "    x = self.tanh(x)\n",
        "    x = change_tensor_values(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n",
        "\n",
        "model = LeNet()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JegPc_r6h7cU"
      },
      "outputs": [],
      "source": [
        "# x = torch.randn(64,1,32,32).type(torch.cuda.FloatTensor)\n",
        "# model = model().to(device)\n",
        "# x = torch.randn(64,1,32,32)\n",
        "# output = model(x)\n",
        "# print(output.shape)\n",
        "# summary(model, (1,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcql3rGfMPiz"
      },
      "source": [
        "# Loading MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NC71TWVL-qb",
        "outputId": "4dce5751-e336-4efd-e9e1-24e4b35bd9fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 167604799.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24986735.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 38545607.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 16681723.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.Compose([transforms.Pad(2), transforms.ToTensor()]), download=True)\n",
        "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.Compose([transforms.Pad(2), transforms.ToTensor()]), download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "dataset_sizes = {'train':len(train_dataset), 'test':len(test_dataset)}\n",
        "\n",
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "yj9gtF1eUmXq",
        "outputId": "d502a69d-d17f-4a77-8037-98f9b604d47c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 16033.8848   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 0.26723140478134155\n",
            "Validation loss: 0.20391511917114258\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 11666.1924   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 0.19443653523921967\n",
            "Validation loss: 0.1866968870162964\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 10897.3750   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 0.1816229224205017\n",
            "Validation loss: 0.19128583371639252\n",
            "Training complete in 296m 17s\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "class ProgressMonitor(object):\n",
        "    \"\"\"\n",
        "    Custom IPython progress bar for training\n",
        "    \"\"\"\n",
        "\n",
        "    tmpl = \"\"\"\n",
        "        <p>Loss: {loss:0.4f}   {value} / {length}</p>\n",
        "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0), display_id=True)\n",
        "\n",
        "    def html(self, count, loss):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
        "\n",
        "    def update(self, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss))\n",
        "\n",
        "def train_new(model,criterion,optimizer,num_epochs,dataloaders,dataset_sizes,first_epoch=1):\n",
        "  since = time.time()\n",
        "  best_loss = 999999\n",
        "  best_epoch = -1\n",
        "  last_train_loss = -1\n",
        "  plot_train_loss = []\n",
        "  plot_valid_loss = []\n",
        "\n",
        "\n",
        "  for epoch in range(first_epoch, first_epoch + num_epochs):\n",
        "      print()\n",
        "      print('Epoch', epoch)\n",
        "      running_loss = 0.0\n",
        "      valid_loss = 0.0\n",
        "\n",
        "      # train phase\n",
        "      model.train()\n",
        "\n",
        "      # create a progress bar\n",
        "      progress = ProgressMonitor(length=dataset_sizes[\"train\"])\n",
        "\n",
        "      for data in dataloaders[0]:\n",
        "          # Move the training data to the GPU\n",
        "          inputs, labels  = data\n",
        "          batch_size = inputs.shape[0]\n",
        "\n",
        "          inputs = Variable(inputs.to(device))\n",
        "          labels = Variable(labels.to(device))\n",
        "\n",
        "          # clear previous gradient computation\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.data * batch_size\n",
        "          # update progress bar\n",
        "          progress.update(batch_size, running_loss)\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[\"train\"]\n",
        "      print('Training loss:', epoch_loss.item())\n",
        "      writer.add_scalar('Training Loss', epoch_loss, epoch)\n",
        "      plot_train_loss.append(epoch_loss)\n",
        "\n",
        "      # validation phase\n",
        "      model.eval()\n",
        "      # We don't need gradients for validation, so wrap in\n",
        "      # no_grad to save memory\n",
        "      with torch.no_grad():\n",
        "        for data in dataloaders[-1]:\n",
        "            inputs, labels  = data\n",
        "            batch_size = inputs.shape[0]\n",
        "\n",
        "            inputs = Variable(inputs.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # calculate the loss\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # update running loss value\n",
        "            valid_loss += loss.data * batch_size\n",
        "\n",
        "      epoch_valid_loss = valid_loss / dataset_sizes[\"test\"]\n",
        "      print('Validation loss:', epoch_valid_loss.item())\n",
        "      plot_valid_loss.append(epoch_valid_loss)\n",
        "      writer.add_scalar('Validation Loss', epoch_valid_loss, epoch)\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "  return plot_train_loss, plot_valid_loss, model\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  train_losses, valid_losses, model = train_new(model = model ,criterion = criterion,optimizer = optimizer,\n",
        "                                              num_epochs=3,dataloaders = [train_loader, test_loader],dataset_sizes = dataset_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlGGwg81bQ-5",
        "outputId": "092b06b7-f764-465d-f342-ee845b3ad2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Predicted 56757 correctly out of 60000 from training dataset, Acuracy : 94.59\n",
            "Model Predicted 9430 correctly out of 10000 from testing dataset, Acuracy : 94.30\n"
          ]
        }
      ],
      "source": [
        "def accuracy(loader, model, train=True):\n",
        "    num_correct = num_samples = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for data in loader:\n",
        "        inputs, labels  = data\n",
        "        batch_size = inputs.shape[0]\n",
        "\n",
        "        inputs = Variable(inputs.to(device))\n",
        "        labels = Variable(labels.to(device))\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = outputs.max(1)\n",
        "        num_correct += (preds == labels).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    accuracy = (num_correct.item()/num_samples)*100\n",
        "    if train:\n",
        "      print(\"Model Predicted {} correctly out of {} from training dataset, Acuracy : {:.2f}\".format(num_correct.item(), num_samples, accuracy))\n",
        "    else:\n",
        "      print(\"Model Predicted {} correctly out of {} from testing dataset, Acuracy : {:.2f}\".format(num_correct.item(), num_samples, accuracy))\n",
        "    model.train()\n",
        "\n",
        "accuracy(train_loader, model)\n",
        "accuracy(test_loader, model, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2w-uPFTdCQd3",
        "outputId": "e4e8165c-46a2-49d5-bd85-6877a4c52daa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-027718821bf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Start tensorboard (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "writer.add_graph(model,x)\n",
        "writer.close()\n",
        "\n",
        "# Start tensorboard (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO3zXz3bP7Lj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Architecture & Implementation of LeNet from Scratch in Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
